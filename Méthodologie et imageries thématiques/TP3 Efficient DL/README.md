# TP3 â€” Efficient DL : Knowledge Distillation

**Master 2 VMI â€” IFLCE075 MÃ©thodologie et Imageries ThÃ©matiques**

Ce TP porte sur la **Knowledge Distillation (KD)** : transfÃ©rer les connaissances d'un Teacher (ResNet50) vers un Student (ResNet18) sur **CIFAR-10**.

---

## ğŸ¯ Objectif

Compresser un grand modÃ¨le tout en conservant (ou dÃ©passant) ses performances via l'apprentissage par distillation :

- **Teacher** : ResNet50 prÃ©-entraÃ®nÃ© ImageNet, fine-tunÃ© sur CIFAR-10
- **Student** : ResNet18 (baseline ou avec KD)
- **KD logits** : distillation des sorties (scores)
- **KD features** : distillation des cartes de caractÃ©ristiques intermÃ©diaires

---

## ğŸ“ Structure du projet

```
TP3 Efficient DL/
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ EfficientDL_KD_Lab.ipynb   # Notebook principal
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ comparaison_finale.png     # Comparaison validation
â”‚   â””â”€â”€ comparison_test_accuracy.png
â”œâ”€â”€ report/
â”‚   â”œâ”€â”€ KD_LAB.pdf                 # Rapport final
â”‚   â””â”€â”€ KD_LAB.tex
â””â”€â”€ README.md
```

---

## ğŸ“Š RÃ©sultats (test accuracy)

| ModÃ¨le | Test accuracy |
|--------|---------------|
| Teacher (ResNet50) | 0.9297 |
| Student baseline (ResNet18, pretrained) | 0.9213 |
| Student KD logits (ResNet18, pretrained) | **0.9312** |

La figure globale inclut aussi KD features et la stratÃ©gie student *from scratch*.

---

## âš™ï¸ PrÃ©requis

- **Google Colab** recommandÃ© (GPU)
- Python â‰¥ 3.10, PyTorch, torchvision, matplotlib, tqdm

```bash
pip install -U torch torchvision tqdm matplotlib
```

---

## â–¶ï¸ ExÃ©cution (Colab)

1. Monter Google Drive et dÃ©finir `CKPT_DIR` :

```python
from google.colab import drive
drive.mount('/content/drive')
CKPT_DIR = "/content/drive/MyDrive/KD_checkpoints"
```

2. ExÃ©cuter le notebook â€” mode **train OR load** : si un checkpoint existe, il est chargÃ© ; sinon, entraÃ®nement puis sauvegarde.

### Checkpoints attendus

`teacher_resnet50_best.pt`, `student_pretrained_baseline_best.pt`, `student_pretrained_kd_logits_best.pt`, `student_pretrained_kd_features_best.pt`, `student_scratch_baseline_best.pt`, `student_scratch_kd_scores_best.pt`

---

## ğŸ“ Configuration

- Split : 45 000 train / 5 000 val / 10 000 test
- Seed : `42` (reproductibilitÃ©)
- HyperparamÃ¨tres dÃ©taillÃ©s dans le rapport

---

## ğŸ‘¤ Auteur

**Wassim Chikhi** â€” Master 2 VMI â€” UniversitÃ© Paris CitÃ© â€” 2025/2026
