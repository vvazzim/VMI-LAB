# MÃ©thodologie et imageries thÃ©matiques  
## Master 2 Vision et Machines Intelligentes (VMI) â€” UniversitÃ© Paris CitÃ©

Ce dossier regroupe les travaux du module **MÃ©thodologie et Imageries ThÃ©matiques** (IFLCE075), couvrant le traitement de la couleur en vision computationnelle et pathologie, ainsi que l'apprentissage profond efficient (Knowledge Distillation).

**Responsable du module :** Nicolas LomÃ©nie

---

## ğŸ¯ Objectif du module

Explorer des mÃ©thodes avancÃ©es en vision par ordinateur et imagerie mÃ©dicale :

- **Perception et traitement de la couleur** : espaces couleur, dÃ©convolution pour la pathologie computationnelle
- **Deep Learning efficient** : Knowledge Distillation pour compresser et transfÃ©rer les connaissances d'un grand modÃ¨le vers un modÃ¨le lÃ©ger

---

## ğŸ—‚ Structure du module

```
MÃ©thodologie et imageries thÃ©matiques/
â”‚
â”œâ”€â”€ README.md                   # Ce fichier
â”‚
â”œâ”€â”€ TP2 Color Supp/             # TP â€” Couleur et dÃ©convolution
â”‚   â”œâ”€â”€ notebook/
â”‚   â”‚   â””â”€â”€ tp-color-supp.ipynb
â”‚   â”œâ”€â”€ figures/                # RÃ©sultats visuels
â”‚   â”œâ”€â”€ report/
â”‚   â”‚   â””â”€â”€ TP_Color_Wassim_compressed.pdf
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ TP3 Efficient DL/           # TP â€” Knowledge Distillation
    â”œâ”€â”€ notebook/
    â”‚   â””â”€â”€ EfficientDL_KD_Lab.ipynb
    â”œâ”€â”€ figures/
    â”œâ”€â”€ report/
    â”‚   â”œâ”€â”€ KD_LAB.pdf
    â”‚   â””â”€â”€ KD_LAB.tex
    â””â”€â”€ README.md
```

---

## ğŸ“š TPs rÃ©alisÃ©s

### ğŸ¨ TP2 â€” Couleur : espaces et dÃ©convolution

**Objectif :** MaÃ®triser les espaces couleur (RGB, CIELab), la luminance, la densitÃ© optique et la **dÃ©convolution de Ruifrok & Johnston** pour les colorations histologiques (H&E, H-DAB).

**Contenu :** Color Display Paradox, comparaison Y vs L*, dÃ©convolution H&E/H-DAB, application sur images rÃ©elles (YTMA10).

ğŸ“ Dossier : [`TP2 Color Supp/`](TP2%20Color%20Supp/) | Rapport : `TP2 Color Supp/report/TP_Color_Wassim_compressed.pdf`

---

### âš¡ TP3 â€” Efficient DL : Knowledge Distillation

**Objectif :** Compresser un Teacher (ResNet50) vers un Student (ResNet18) sur CIFAR-10 via Knowledge Distillation (logits et feature maps).

**RÃ©sultats :**

| ModÃ¨le | Test accuracy |
|--------|---------------|
| Teacher (ResNet50) | 0.9297 |
| Student baseline (ResNet18, pretrained) | 0.9213 |
| Student KD logits (ResNet18, pretrained) | **0.9312** |

ğŸ“ Dossier : [`TP3 Efficient DL/`](TP3%20Efficient%20DL/) | Rapport : `TP3 Efficient DL/report/KD_LAB.pdf`

---

## âš™ï¸ Environnement

**TP2 Color :** `numpy`, `scipy`, `scikit-image`, `matplotlib`, `opencv-python`, `pillow`

**TP3 Efficient DL :** `torch`, `torchvision`, `matplotlib`, `tqdm` â€” exÃ©cution recommandÃ©e sur **Google Colab** (GPU)

---

## ğŸ‘¤ Auteur

**Wassim Chikhi** â€” Master 2 VMI â€” UniversitÃ© Paris CitÃ© â€” 2025/2026
