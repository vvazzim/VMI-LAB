# TP3 ‚Äî Apprentissage Auto-Supervis√© (SSL)
**Auteur : Wassim CHIKHI ‚Äî M2 VMI 2025**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vvazzim/Tp-VMI-Wassim/blob/main/deep-learning/tp3-self-supervised-learning/notebooks/Self_Supervised_Learning_Demos_final.ipynb)

---

## Objectif
Explorer et comparer plusieurs **t√¢ches pr√©textes** en apprentissage auto-supervis√© (SSL) sur **CIFAR-10** et **STL-10**, afin d‚Äô√©valuer leur capacit√© √† apprendre des repr√©sentations transf√©rables vers des t√¢ches de classification supervis√©e (linear probe).

---

## Configuration
- **Encodeur** : ResNet-18  
- **Optimiseur** : Adam *(lr = 0.001, batch = 256)*  
- **Datasets** : CIFAR-10 (32√ó32), STL-10 (96√ó96)  
- **Entra√Ænement** : 20 epochs (pr√©texte) + 5 epochs (linear probe)  
- **Plateforme** : Google Colab (GPU T4)

---

## M√©thodologie
- Impl√©mentation de la t√¢che pr√©texte **Relative Patch Location** (Doersch et al., 2015).  
- Comparaison avec trois autres approches : **Rotation Prediction**, **Inpainting**, **SimCLR**.  
- √âvaluation : entra√Ænement d‚Äôun **classifieur lin√©aire** sur les repr√©sentations gel√©es.  
- Mesure : **Accuracy downstream** sur les deux datasets.

---

## R√©sultats (linear probe)

| T√¢che pr√©texte | CIFAR-10 | STL-10 |
|----------------|-----------|--------|
| Relative Patch | **35.8 %** | **25.1 %** |
| Rotation       | **43.7 %** | **43.1 %** |
| Inpainting     | **40.2 %** | **27.3 %** |
| SimCLR         | **44.6 %** | **41.1 %** |

**Analyse :**  
- *Relative Patch* ‚Üí capte bien la g√©om√©trie locale mais peine √† g√©n√©raliser.  
- *Rotation* ‚Üí meilleure compr√©hension globale, tr√®s stable entre datasets.  
- *Inpainting* ‚Üí correct sur CIFAR-10, limit√© sur STL-10.  
- *SimCLR* ‚Üí excellentes performances gr√¢ce √† son apprentissage contrastif.

---

## Conclusion
Les t√¢ches **globales ou contrastives** (SimCLR, Rotation) fournissent les meilleures repr√©sentations pour le transfert.  
*Relative Patch* reste pertinente comme compl√©ment g√©om√©trique dans des approches multi-t√¢ches.

**Perspectives :**
- Entra√Ænement plus long (epochs ‚Üë)  
- Fine-tuning de l‚Äôencodeur  
- Fusion de plusieurs t√¢ches pr√©textes

---

## Liens utiles  
- Notebook Colab : [`notebooks/Self_Supervised_Learning_Demos_final.ipynb`](./notebooks/Self_Supervised_Learning_Demos_final.ipynb)  
- Rapport PDF : [`rapport/rapport_SSL.pdf`](./rapport/rapport_SSL.pdf)

---

## üìö R√©f√©rences
- Doersch M. et al. *Unsupervised visual representation learning by context prediction* (ICCV 2015).  
- Gidaris S. et al. *Unsupervised representation learning by predicting image rotations* (arXiv 2018).  
- Chen T. et al. *SimCLR: A Simple Framework for Contrastive Learning* (arXiv 2020).  
- Pathak D. et al. *Context Encoders: Feature Learning by Inpainting* (CVPR 2016).  
