# ğŸ§  Vision & Machines Intelligentes (VMI) â€” Master 2 Lab Repository

**Auteur :** Wassim CHIKHI  
**AnnÃ©e :** 2025  
**Master 2 â€” Parcours Vision et Machines Intelligentes (VMI)**  
**UniversitÃ© Paris CitÃ©**

---

## ğŸ¯ Objectif du dÃ©pÃ´t

Ce dÃ©pÃ´t constitue **l'ensemble des travaux du Master 2 VMI** : Travaux Pratiques, projets mÃ©thodologiques et rapports scientifiques rÃ©alisÃ©s tout au long de l'annÃ©e universitaire.

**Objectif :** offrir une **organisation claire, reproductible et documentÃ©e** de tous les projets â€” notebooks Colab, pipelines Python, scripts ICY, rapports LaTeX â€” pour servir de rÃ©fÃ©rence et de portfolio acadÃ©mique.

---

## ğŸ—‚ï¸ Structure gÃ©nÃ©rale

```
Tp-VMI-Wassim/
â”‚
â”œâ”€â”€ reco-forme-avancee/          # Reconnaissance de Formes AvancÃ©e
â”‚   â””â”€â”€ tp1-fuzzy-cmeans/
â”‚       â”œâ”€â”€ notebooks/
â”‚       â”œâ”€â”€ data/
â”‚       â””â”€â”€ rapport/
â”‚
â”œâ”€â”€ deep-learning/               # Deep Learning
â”‚   â”œâ”€â”€ tp1-mlp-mnist/
â”‚   â”œâ”€â”€ tp2-cnn-transfer-learning/
â”‚   â””â”€â”€ tp3-self-supervised-learning/
â”‚
â”œâ”€â”€ imagerie-biomed/             # Imagerie BiomÃ©dicale
â”‚   â”œâ”€â”€ Tp1-Modalities/
â”‚   â”œâ”€â”€ TP2-Spots/
â”‚   â””â”€â”€ TP3/                     # Segmentation & Tracking HeLa
â”‚
â”œâ”€â”€ 3d/                          # Imagerie 3D / PhotogrammÃ©trie
â”‚   â”œâ”€â”€ tp1/
â”‚   â”‚   â””â”€â”€ TP2 Drone GCP/       # Photos drone + GCPs
â”‚   â””â”€â”€ Projet Final/
â”‚
â”œâ”€â”€ MÃ©thodologie et imageries thÃ©matiques/
â”‚   â”œâ”€â”€ TP2 Color Supp/          # Couleur, dÃ©convolution H&E / H-DAB
â”‚   â””â”€â”€ TP3 Efficient DL/        # Knowledge Distillation
â”‚
â”œâ”€â”€ ModÃ©lisation de systÃ¨mes intelligents/
â”‚   â”œâ”€â”€ 7th Meth 1/              # Classification WSI (DINOv2, SPPR)
â”‚   â”œâ”€â”€ state of the art/
â”‚   â””â”€â”€ UNI/
â”‚
â”œâ”€â”€ Multi-modalitÃ© et IA gÃ©nÃ©rative/
â”‚   â”œâ”€â”€ LLM_LAB/                 # LLM, classification sentiments
â”‚   â”œâ”€â”€ TP2 CLIP/                # CLIP multimodal, ROCO, CIFAR10
â”‚   â””â”€â”€ TP 3 GaN-VAE/            # VAE / GAN (sprites PokÃ©mon)
â”‚
â”œâ”€â”€ SeqVid/                      # SÃ©quences VidÃ©o
â”‚   â”œâ”€â”€ TP1/                     # Calibration camÃ©ra
â”‚   â”œâ”€â”€ TP2/                     # Flot optique
â”‚   â””â”€â”€ TP3/                     # Multi-object tracking (CSRT, YOLO)
â”‚
â””â”€â”€ docs/
    â””â”€â”€ templates/
```

---

## ğŸ§© Modules et TPs rÃ©alisÃ©s

### ğŸ§© Reconnaissance de Formes AvancÃ©e
- **TP1 â€” Fuzzy C-Means (Segmentation floue)**  
  ImplÃ©mentation *from scratch* du Fuzzy C-Means appliquÃ© Ã  la segmentation d'images (GRAY C=2, RGB C=3).  
  Notebook : `reco-forme-avancee/tp1-fuzzy-cmeans/notebooks/TP_Fuzzy_C_Means3_0.ipynb`  
  Rapport : `reco-forme-avancee/tp1-fuzzy-cmeans/rapport/rapport_fcm.pdf`

---

### ğŸ¤– Deep Learning
- **TP1 â€” MLP sur MNIST** : introduction au Deep Learning supervisÃ© (classification).  
- **TP2 â€” CNN & Transfer Learning (ResNet18)** : fine-tuning sur datasets standards.  
- **TP3 â€” Self-Supervised Learning (SSL)** : comparaison de tÃ¢ches prÃ©textes (Rotation, Relative Patch, SimCLR, Inpainting) sur CIFAR-10 / STL-10.  
  Rapport : `deep-learning/tp3-self-supervised-learning/rapport/rapport_SSL.pdf`

---

### ğŸ§¬ Imagerie BiomÃ©dicale
- **TP1 â€” Imagerie Photonique : ModalitÃ©s et Photoblanchiment**  
  Ã‰tude des modalitÃ©s de microscopie optique (champ clair, fluorescence, confocale) et mesure du photoblanchiment.  
  Rapport : `imagerie-biomed/Tp1-Modalities/report/TP_1_BioImg_Wassim.pdf`

- **TP2 â€” DÃ©tection et Tracking de Spots sous ICY**  
  Pipeline ICY (Wavelet Spot Detector + Kalman) + scripts Python/Jython pour automatisation.  
  Rapport : `imagerie-biomed/TP2-Spots/report/TP_2_BioImg_Wassim.pdf`

- **TP3 â€” Segmentation et Tracking de cellules HeLa**  
  Segmentation avec **Cellpose** + tracking avec **TrackPy** ; comparaison approche ICY vs Python.  
  Rapport : `imagerie-biomed/TP3/report/TP3_CellSegmentation_Tracking_Wassim.pdf`

---

### ğŸ•¹ï¸ Imagerie 3D
- **tp1 â€” TP2 Drone GCP** : donnÃ©es photogrammÃ©triques (photos drone P4 RTK, GCPs).  
- **Projet Final** : livrables et rendus du projet de photogrammÃ©trie 3D.

---

### ğŸ“ MÃ©thodologie et Imageries ThÃ©matiques
- **TP2 â€” Couleur** : espaces RGB/CIELab, luminance, dÃ©convolution Ruifrok & Johnston (H&E, H-DAB).  
  Rapport : `MÃ©thodologie et imageries thÃ©matiques/TP2 Color Supp/report/TP_Color_Wassim_compressed.pdf`

- **TP3 â€” Efficient DL (Knowledge Distillation)** : ResNet50 â†’ ResNet18 sur CIFAR-10 (logits + feature maps).  
  Rapport : `MÃ©thodologie et imageries thÃ©matiques/TP3 Efficient DL/report/KD_LAB.pdf`

---

### ğŸ”¬ ModÃ©lisation de SystÃ¨mes Intelligents
- **Projet â€” Classification de lames histologiques (WSI)**  
  Pipeline DINOv2 + SPPR (chemins alÃ©atoires) pour classification WSI en supervision faible.  
  Rapport : `ModÃ©lisation de systÃ¨mes intelligents/7th Meth 1/report/Rapport_SPPR.pdf`  
  Slides : `ModÃ©lisation de systÃ¨mes intelligents/7th Meth 1/slides/Classification_de_lames_histologiques_by_Wassim_V4.pdf`  
- **Ã‰tat de l'art** et article UNI dans les sous-dossiers dÃ©diÃ©s.

---

### ğŸ¨ Multi-modalitÃ© et IA GÃ©nÃ©rative
- **LLM Lab** : adaptation de RoBERTa pour classification de sentiments (inference, linear probing, fine-tuning).  
  Rapport : `Multi-modalitÃ© et IA gÃ©nÃ©rative/LLM_LAB/report/TP_LLM.pdf`

- **TP2 â€” CLIP** : apprentissage multimodal texte-image, fine-tuning sur ROCO, zero-shot CIFAR10.  
  Rapport : `Multi-modalitÃ© et IA gÃ©nÃ©rative/TP2 CLIP/repport/TP2_CLIP_r.pdf`

- **TP3 â€” GAN & VAE** : gÃ©nÃ©ration de sprites PokÃ©mon (DCGAN, VAE convolutionnel).  
  Rapport : `Multi-modalitÃ© et IA gÃ©nÃ©rative/TP 3 GaN-VAE/TP_GaN_VAE_WASSIM (1).pdf`

---

### ğŸ¬ SÃ©quences VidÃ©o (SeqVid)
- **TP1** : Calibration camÃ©ra.  
- **TP2** : Flot optique.  
- **TP3 â€” Multi-Object Tracking** : CSRT (OpenCV), YOLOv8 + IoU, bonus Kalman.  
  Rapport : `SeqVid/TP3/report/TP3_SeqVid_Wassim.pdf`

---

## âš™ï¸ Workflow de travail

### Sur **Google Colab**
1. Ouvrir le notebook via le badge Â« Open in Colab Â».  
2. Monter le Drive :  
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```
3. Charger les donnÃ©es depuis Drive / URL.  
4. ExÃ©cuter les cellules, documenter, sauvegarder.  
5. Exporter le notebook â†’ Â« Save a copy to GitHub Â».

### Sur **ICY / Local**
- Lancer ICY, importer les images `.tif`.  
- Utiliser les plugins : *Spot Detector*, *Track Manager*, *ROI Statistics*.  
- Exporter les rÃ©sultats (.xml, .xlsx) vers le dossier `result/`.

---

## ğŸ§¾ Rapports et documentation
- Chaque TP contient un **rapport LaTeX** compilÃ© en PDF dans `rapport/` ou `report/`.  
- Figures, tables et lÃ©gendes sont reliÃ©es aux donnÃ©es ICY, NumPy ou Matplotlib selon le TP.  
- Chaque module dispose de son propre `README.md` pour les dÃ©tails spÃ©cifiques.  
- ModÃ¨les (templates) pour TPs et rapports : `docs/templates/` (voir `docs/README.md`).

---

## âš™ï¸ Environnement

Chaque module peut dÃ©finir ses propres dÃ©pendances. Exemples :

**SeqVid TP3** (tracking) :
```bash
conda create -n seqvid python=3.10
conda activate seqvid
pip install -r SeqVid/TP3/requirements.txt
```

**Librairies courantes** :  
`numpy`, `matplotlib`, `scikit-image`, `torch`, `torchvision`, `opencv-python`, `tifffile`, `scipy`, `ultralytics`, `transformers`, `cellpose`, `trackpy`.

---

## ğŸ“˜ RÃ©fÃ©rences principales
- Olivo-Marin, *Wavelet-based detection of spots and features in biological images*, IEEE, 2002.  
- Ronneberger et al., *U-Net: Convolutional Networks for Biomedical Image Segmentation*, MICCAI, 2015.  
- Gidaris et al., *Unsupervised Representation Learning by Predicting Image Rotations*, 2018.  
- Chen et al., *SimCLR: A Simple Framework for Contrastive Learning*, 2020.  
- Ruifrok & Johnston, *Quantification of histochemical staining by color deconvolution*, J Histochem Cytochem, 2001.  
- Cours Master 2 VMI â€” UniversitÃ© Paris CitÃ©.

---

## âš–ï¸ Licence
Projet acadÃ©mique â€” **Licence MIT**  
Â© 2025 â€” *Wassim CHIKHI*
