# ğŸ§  Travaux Pratiques â€” Vision & Machines Intelligentes (VMI)
**Auteur :** Wassim CHIKHI  
**AnnÃ©e :** 2025  
**Master 2 â€” Parcours Vision et Machines Intelligentes (VMI)**  
**UniversitÃ© Paris CitÃ©**

---

## ğŸ¯ Objectif du dÃ©pÃ´t
Ce dÃ©pÃ´t regroupe **lâ€™ensemble des Travaux Pratiques du Master 2 VMI**, rÃ©partis en quatre grands modules :  
- ğŸ§© **Reconnaissance de Formes AvancÃ©e (RecoForme)**  
- ğŸ¤– **Deep Learning (DL)**  
- ğŸ§¬ **Imagerie BiomÃ©dicale (BioImg)**  
- ğŸ•¹ï¸ **Imagerie 3D (3D Vision)**  

Lâ€™objectif est de proposer une **organisation claire, reproductible et documentÃ©e** de tous les TPs rÃ©alisÃ©s en Colab, ICY ou Python.

---

## ğŸ—‚ï¸ Structure gÃ©nÃ©rale
```
Tp-VMI-Wassim/
â”œâ”€ reco-forme-avancee/
â”‚  â””â”€ tp1-fuzzy-cmeans/
â”‚     â”œâ”€ notebooks/
â”‚     â”œâ”€ data/
â”‚     â””â”€ rapport/
â”‚
â”œâ”€ deep-learning/
â”‚  â”œâ”€ tp1-mlp-mnist/
â”‚  â”œâ”€ tp2-cnn-transfer-learning/
â”‚  â””â”€ tp3-self-supervised-learning/
â”‚
â”œâ”€ imagerie-biomed/
â”‚  â”œâ”€ tp1-modalities/
â”‚  â”œâ”€ tp2-spots/
â”‚  â””â”€ tp3-segmentation/ (Ã  venir)
â”‚
â”œâ”€ 3d/
â”‚  â””â”€ tp1-bases/
â”‚
â””â”€ docs/templates/
```

---

## ğŸ§© Modules et TPs rÃ©alisÃ©s

### ğŸ§  Reconnaissance de Formes AvancÃ©e
- **TP1 â€” Fuzzy C-Means (Segmentation floue)**  
  ImplÃ©mentation Python du Fuzzy C-Means appliquÃ© Ã  la segmentation dâ€™images.  
  Notebook disponible sous :  
  `reco-forme-avancee/tp1-fuzzy-cmeans/notebooks/FCM_TP_Etudiant.ipynb`

---

### ğŸ¤– Deep Learning
- **TP1 â€” MLP sur MNIST** : introduction au Deep Learning supervisÃ© (classification simple).  
- **TP2 â€” CNN & Transfer Learning (ResNet18)** : apprentissage par fine-tuning.  
- **TP3 â€” Self-Supervised Learning (SSL)** : comparaison de tÃ¢ches prÃ©textes (Rotation, Relative Patch, SimCLR, Inpainting).  
  Rapport : `deep-learning/tp3-self-supervised-learning/rapport/CHIKHI_Wassim_TP_SSL_VMI2025.pdf`

---

### ğŸ§¬ Imagerie BiomÃ©dicale
- **TP1 â€” Imagerie Photonique : ModalitÃ©s et Fluorescence**  
  Ã‰tude des principes de microscopie optique et du photoblanchiment.  
  Rapport : `imagerie-biomed/tp1-modalities/report/TP_1_BioImg.pdf`

- **TP2 â€” DÃ©tection et Tracking de Spots sous ICY**  
  Mise en Å“uvre dâ€™un pipeline complet ICY (Wavelet Spot Detector + Kalman Tracking).  
  Rapport : `imagerie-biomed/tp2-spots/report/TP_2_BioImg_Wassim.pdf`

- **TP3 â€” Segmentation et MorphomÃ©trie (Ã  venir)**  
  Application dâ€™algorithmes de segmentation (U-Net, Watershed).

---

### ğŸ•¹ï¸ Imagerie 3D
- **TP1 â€” Bases du traitement 3D**  
  Chargement, visualisation et analyse de nuages de points (Open3D, ICP).  
  *PrÃ©vu pour la fin du semestre.*

---

## âš™ï¸ Workflow de travail
### Sur **Google Colab**
1. Ouvrir le notebook via le badge â€œOpen in Colabâ€.  
2. Monter le Drive :  
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```
3. Charger les donnÃ©es depuis Drive / URL.  
4. ExÃ©cuter les cellules, documenter, sauvegarder.  
5. Exporter le notebook â†’ â€œSave a copy to GitHubâ€.

### Sur **ICY / Local**
- Lancer ICY, importer les images `.tif`.  
- Utiliser les plugins : *Spot Detector*, *Track Manager*, *ROI Statistics*.  
- Exporter les rÃ©sultats (.xml, .xlsx) vers le dossier `result/`.

---

## ğŸ§¾ Rapports et documentation
- Chaque TP contient un **rapport LaTeX** compilÃ© en PDF dans `rapport/` ou `report/`.  
- Tous les rapports utilisent la **classe tau** (`tau-class/tau.cls`) pour uniformiser la mise en page.  
- Figures, tables et lÃ©gendes sont reliÃ©es aux donnÃ©es ICY, NumPy ou Matplotlib selon le TP.

---

## âš™ï¸ Environnement
**Option Conda :**
```bash
conda env create -f env/environment.yml
conda activate vmi
```

**Option pip :**
```bash
pip install -r env/requirements.txt
```

Librairies clÃ©s :  
`numpy`, `matplotlib`, `scikit-image`, `torch`, `torchvision`, `opencv-python`, `tifffile`, `scipy`.

---

## ğŸ“˜ RÃ©fÃ©rences principales
- Olivo-Marin, *Wavelet-based detection of spots and features in biological images*, IEEE, 2002.  
- Ronneberger et al., *U-Net: Convolutional Networks for Biomedical Image Segmentation*, MICCAI, 2015.  
- Gidaris et al., *Unsupervised Representation Learning by Predicting Image Rotations*, 2018.  
- Chen et al., *SimCLR: A Simple Framework for Contrastive Learning*, 2020.  
- Cours Master 2 VMI â€” Camille Kurtz.

---

## âš–ï¸ Licence
Projet acadÃ©mique â€” **Licence MIT**  
Â© 2025 â€” *Wassim CHIKHI*
