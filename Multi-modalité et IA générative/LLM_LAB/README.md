# Lab â€“ Large Language Models (LLM)
**Master 2 Informatique â€“ Parcours VMI**  
**Multi-modalitÃ© et IA gÃ©nÃ©rative (IFLCE055)**

Ce dÃ©pÃ´t contient le notebook et le rapport associÃ©s au TP sur lâ€™adaptation de modÃ¨les de langage prÃ©â€‘entraÃ®nÃ©s (LLMs) pour une tÃ¢che de **classification de sentiments**.

---

## ğŸš€ Lancer le notebook sur Google Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ZTCXM_edq0ysQlmLN5ZBcO8p9mmLQL5w?usp=sharing)

---

## ğŸ“Œ Objectifs du TP

Explorer et comparer **trois stratÃ©gies** dâ€™adaptation dâ€™un LLM Ã  une tÃ¢che aval :

1. **Inference without training**  
   Utilisation du modÃ¨le prÃ©â€‘entraÃ®nÃ© tel quel (zÃ©ro entraÃ®nement).
2. **Linear Probing**  
   Gel du backbone et entraÃ®nement uniquement de la tÃªte de classification.
3. **Fineâ€‘tuning**  
   - Fineâ€‘tuning complet (tous les paramÃ¨tres entraÃ®nables)  
   - Fineâ€‘tuning partiel (certaines couches gelÃ©es)

Une section dÃ©diÃ©e Ã  lâ€™**analyse des tokens, IDs et embeddings** est Ã©galement incluse.

---

## ğŸ§  ModÃ¨le et donnÃ©es

- **Dataset** : `cornell-movie-review-data/rotten_tomatoes`  
  - Train : 8â€¯530  
  - Validation : 1â€¯066  
  - Test : 1â€¯066  
- **ModÃ¨le** : `cardiffnlp/twitter-roberta-base-sentiment-latest` (RoBERTa)

La tÃ¢che cible est **binaire** (NEGATIVE / POSITIVE).  
La tÃªte de classification du modÃ¨le est donc rÃ©initialisÃ©e en 2 classes lorsque nÃ©cessaire.

---

## ğŸ“Š MÃ©triques dâ€™Ã©valuation

Pour garantir une comparaison cohÃ©rente entre toutes les approches :

- **Accuracy** â†’ performance quantitative globale  
- **F1â€‘score (binaire)** â†’ qualitÃ© de la classification

Une **matrice de confusion** (fineâ€‘tuning complet) et une **figure de comparaison globale**
(bar plot Accuracy / F1) sont incluses.

---

## ğŸ“ Contenu du projet

```
.
â”œâ”€â”€ LLM_Lab.ipynb              # Notebook principal (expÃ©riences complÃ¨tes)
â”œâ”€â”€ TP_LLM.pdf                 # Rapport final (LaTeX â†’ PDF)
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ performance_comparison.png
â”‚   â””â”€â”€ confusion_matrix_finetune.png
â””â”€â”€ README.md
```

---

## â–¶ï¸ ExÃ©cution

Le notebook est conÃ§u pour Ãªtre exÃ©cutÃ© **directement sur Google Colab**.

### DÃ©pendances principales
- `transformers`
- `datasets`
- `torch`
- `scikit-learn`
- `matplotlib`

Les datasets et modÃ¨les utilisÃ©s sont **publics**.  
Aucun token Hugging Face nâ€™est requis dans un environnement standard.

---

## ğŸ“ RÃ©sumÃ© des rÃ©sultats (jeu de test)

| Approche | Accuracy | F1-score |
|--------|---------|----------|
| Inference sans entraÃ®nement | 0.751 | 0.742 |
| Linear probing | 0.836 | 0.835 |
| Fineâ€‘tuning complet | 0.877 | 0.874 |
| Fineâ€‘tuning partiel | 0.875 | 0.872 |

Les rÃ©sultats montrent une amÃ©lioration progressive avec le degrÃ© dâ€™adaptation du modÃ¨le,
le fineâ€‘tuning partiel offrant un excellent compromis entre performance et coÃ»t computationnel.

---

## ğŸ‘¤ Auteur

**Wassim Chikhi**  
Master 2 Vision et Machines Intelligentes (VMI)  
UniversitÃ© Paris CitÃ© â€” 2025/2026

---

## ğŸ“„ Licence

Ce projet est fourni dans un cadre acadÃ©mique (TP universitaire).
