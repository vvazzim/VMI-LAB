# TP2 â€” CLIP : Apprentissage Multimodal Texteâ€“Image

**Master 2 VMI â€” UniversitÃ© Paris CitÃ© (2025/2026)**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vvazzim/Tp-VMI-Wassim/blob/main/Multi-modalitÃ©%20et%20IA%20gÃ©nÃ©rative/TP2%20CLIP/notebook/TP_CLIP_Wassim.ipynb)

---

## ğŸ¯ Objectif

Explorer la capacitÃ© du modÃ¨le **CLIP** Ã  aligner images et textes :

- Analyse d'images naturelles avec similaritÃ© texte-image
- Ã‰valuation sur images mÃ©dicales **ROCO** (Radiology Objects in Context)
- Fine-tuning ViT-B/16 sur ROCO
- Comparaison de 5 architectures CLIP (RN50, RN101, RN50x4, ViT-B/32, ViT-B/16)
- Classification zero-shot sur **CIFAR10**

---

## ğŸ“ Structure du projet

```
TP2 CLIP/
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ TP_CLIP_Wassim.ipynb    # Notebook principal
â”œâ”€â”€ figures/                     # Visualisations
â”‚   â”œâ”€â”€ natural_similarity.png
â”‚   â”œâ”€â”€ medical_similarity_finetuned.png
â”‚   â”œâ”€â”€ roco_similarity_pre_vs_ft.png
â”‚   â”œâ”€â”€ model_comparison_scores.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ repport/
â”‚   â””â”€â”€ TP2_CLIP_r.pdf          # Rapport final
â””â”€â”€ README.md
```

---

## ğŸ“¦ DonnÃ©es utilisÃ©es

| Source | Description |
|--------|-------------|
| **Natural images** | 8 images de `skimage.data` avec lÃ©gendes |
| **ROCO** | Radiographies / CT / IRM + lÃ©gendes â€” Ã©valuation & fine-tuning |
| **CIFAR10** | Validation zero-shot |

---

## ğŸ§ª RÃ©sultats principaux

| ExpÃ©rience | RÃ©sultat |
|------------|----------|
| Natural Images | Acc@1 = 100%, Acc@5 = 100% |
| ROCO prÃ©-entraÃ®nÃ© | SimilaritÃ© correcte mais limitÃ©e |
| ROCO fine-tunÃ© | AmÃ©lioration nette du contraste diagonal |
| CIFAR10 zero-shot | Top-1 = 89.16 %, Top-5 = 99.08 % |

---

## âš™ï¸ ModÃ¨les CLIP Ã©valuÃ©s

RN50, RN101, RN50x4, ViT-B/32, ViT-B/16 (fine-tunÃ© sur ROCO)

---

## ğŸ‘¤ Auteur

**Wassim Chikhi** â€” Master 2 VMI â€” UniversitÃ© Paris CitÃ© â€” 2025/2026
